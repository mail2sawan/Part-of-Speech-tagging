{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "print(nltk_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05, random_state =100)\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95949"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'bright', 'sign', 'is', 'that', 'a', 'growing', 'number', 'of', 'women']\n",
      "12106\n"
     ]
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "print(tokens[:10])\n",
    "# vocabulary\n",
    "V = list(set(tokens))\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['CONJ', 'PRT', 'DET', '.', 'NOUN', 'ADV', 'ADP', 'X', 'PRON', 'VERB', 'ADJ', 'NUM']\n"
     ]
    }
   ],
   "source": [
    "# number of tags\n",
    "T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "print(len(T))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission Probabilities and Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag):\n",
    "    tag_list = [pair for pair in train_tagged_words if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag/count_tag)\n",
    "\n",
    "\n",
    "\n",
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1/count_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>DET</th>\n",
       "      <th>.</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADP</th>\n",
       "      <th>X</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.118683</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.350487</td>\n",
       "      <td>0.053778</td>\n",
       "      <td>0.053778</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.058414</td>\n",
       "      <td>0.155308</td>\n",
       "      <td>0.118683</td>\n",
       "      <td>0.042188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.043635</td>\n",
       "      <td>0.245735</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.405184</td>\n",
       "      <td>0.083661</td>\n",
       "      <td>0.056102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>0.637293</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.009618</td>\n",
       "      <td>0.045323</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.040394</td>\n",
       "      <td>0.204977</td>\n",
       "      <td>0.021640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.058032</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.173558</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>0.222531</td>\n",
       "      <td>0.052292</td>\n",
       "      <td>0.092206</td>\n",
       "      <td>0.026908</td>\n",
       "      <td>0.065208</td>\n",
       "      <td>0.088708</td>\n",
       "      <td>0.043681</td>\n",
       "      <td>0.081353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.042921</td>\n",
       "      <td>0.043357</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.239951</td>\n",
       "      <td>0.264280</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.177058</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.146955</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.009550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.014314</td>\n",
       "      <td>0.069907</td>\n",
       "      <td>0.135153</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.077230</td>\n",
       "      <td>0.119507</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.015646</td>\n",
       "      <td>0.344541</td>\n",
       "      <td>0.130160</td>\n",
       "      <td>0.031624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.323969</td>\n",
       "      <td>0.039754</td>\n",
       "      <td>0.321213</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>0.034984</td>\n",
       "      <td>0.069119</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.107389</td>\n",
       "      <td>0.061910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.184891</td>\n",
       "      <td>0.055229</td>\n",
       "      <td>0.162831</td>\n",
       "      <td>0.062371</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.144898</td>\n",
       "      <td>0.074433</td>\n",
       "      <td>0.055705</td>\n",
       "      <td>0.204571</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.040613</td>\n",
       "      <td>0.211494</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.092720</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.484291</td>\n",
       "      <td>0.072031</td>\n",
       "      <td>0.007280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.031427</td>\n",
       "      <td>0.133292</td>\n",
       "      <td>0.034291</td>\n",
       "      <td>0.111386</td>\n",
       "      <td>0.082050</td>\n",
       "      <td>0.091184</td>\n",
       "      <td>0.218438</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.168744</td>\n",
       "      <td>0.065640</td>\n",
       "      <td>0.022448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.016052</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.063882</td>\n",
       "      <td>0.700901</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.078624</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.020803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>0.352347</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.035056</td>\n",
       "      <td>0.211824</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.033571</td>\n",
       "      <td>0.184195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CONJ       PRT       DET         .      NOUN       ADV       ADP  \\\n",
       "CONJ  0.000464  0.003709  0.118683  0.035698  0.350487  0.053778  0.053778   \n",
       "PRT   0.002297  0.001969  0.101050  0.043635  0.245735  0.010171  0.019357   \n",
       "DET   0.000481  0.000240  0.005771  0.017913  0.637293  0.012623  0.009618   \n",
       ".     0.058032  0.002511  0.173558  0.092923  0.222531  0.052292  0.092206   \n",
       "NOUN  0.042921  0.043357  0.013363  0.239951  0.264280  0.016813  0.177058   \n",
       "ADV   0.006991  0.014314  0.069907  0.135153  0.031624  0.077230  0.119507   \n",
       "ADP   0.000848  0.001484  0.323969  0.039754  0.321213  0.013357  0.017492   \n",
       "X     0.010316  0.184891  0.055229  0.162831  0.062371  0.025393  0.144898   \n",
       "PRON  0.004981  0.012261  0.009195  0.040613  0.211494  0.034100  0.023372   \n",
       "VERB  0.005186  0.031427  0.133292  0.034291  0.111386  0.082050  0.091184   \n",
       "ADJ   0.016052  0.010156  0.004914  0.063882  0.700901  0.004914  0.078624   \n",
       "NUM   0.013072  0.026144  0.003862  0.118835  0.352347  0.002674  0.035056   \n",
       "\n",
       "             X      PRON      VERB       ADJ       NUM  \n",
       "CONJ  0.008809  0.058414  0.155308  0.118683  0.042188  \n",
       "PRT   0.013123  0.017717  0.405184  0.083661  0.056102  \n",
       "DET   0.045323  0.003727  0.040394  0.204977  0.021640  \n",
       ".     0.026908  0.065208  0.088708  0.043681  0.081353  \n",
       "NOUN  0.028868  0.004721  0.146955  0.012165  0.009550  \n",
       "ADV   0.023302  0.015646  0.344541  0.130160  0.031624  \n",
       "ADP   0.034984  0.069119  0.008481  0.107389  0.061910  \n",
       "X     0.074433  0.055705  0.204571  0.016505  0.002857  \n",
       "PRON  0.092720  0.007663  0.484291  0.072031  0.007280  \n",
       "VERB  0.218438  0.035916  0.168744  0.065640  0.022448  \n",
       "ADJ   0.020311  0.000491  0.011794  0.067158  0.020803  \n",
       "NUM   0.211824  0.001485  0.016934  0.033571  0.184195  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating t x t transition matrix of tags. Each column is t2, each row is t1. Thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)\n",
    "        \n",
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create plain version of Viterbi Algorithm which can not correctly identify the unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_vanila(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            #emission_p = word_given_tag(words[key], tag)\n",
    "            #word_tag_df\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy of vanila Viterbi alogorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Investors', 'NOUN'), ('took', 'VERB'), ('advantage', 'NOUN'), ('of', 'ADP'), ('Tuesday', 'NOUN'), (\"'s\", 'PRT'), ('stock', 'NOUN'), ('rally', 'NOUN'), ('*-1', 'X'), ('to', 'PRT')]\n",
      "CPU times: user 9min 16s, sys: 3.23 s, total: 9min 20s\n",
      "Wall time: 9min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_seq = Viterbi_vanila(test_tagged_words)\n",
    "print(tagged_seq[:10])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the rule based function which can return the tag based on the pattern defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify patterns for tagging. example from the NLTK book\n",
    "\n",
    "test= 'samsung'\n",
    "\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              \n",
    "    (r'.*ed$', 'VERB'),               \n",
    "    (r'.*es$', 'VERB'),               \n",
    "    (r'.*ly$', 'ADV'),              \n",
    "    (r'.*ble$', 'ADJ'),                \n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), \n",
    "    (r'.*', 'NOUN')                    \n",
    "]\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "def rulebased_tagging(test_words):\n",
    "    return regexp_tagger.tag([test_words])[0][1]\n",
    "\n",
    "def rulebased_tagging1(test_words):\n",
    "    return regexp_tagger.tag([test_words])\n",
    "\n",
    "# rulebased_tagging(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Updated Viterbi Algorithms for different techniques\n",
    "\n",
    "### Probabilistic with Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Viterbi Heuristic\n",
    "\n",
    "def Viterbi_probabilistic(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            #emission_p = word_given_tag(words[key], tag)\n",
    "            #word_tag_df\n",
    "            if(words[key] in V):\n",
    "                emission_p = word_given_tag(words[key], tag)\n",
    "                state_probability = emission_p * transition_p\n",
    "            else:\n",
    "                state_probability = transition_p\n",
    "                                   \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic with rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Viterbi Heuristic\n",
    "\n",
    "def Viterbi_rulebased(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        state_probability = 0\n",
    "        rule_tag = \"\"\n",
    "        if word[key] in v:\n",
    "            for tag in T:     \n",
    "                if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "            \n",
    "            # compute emission and state probabilities           \n",
    "                emission_p = word_given_tag(words[key], tag)\n",
    "                state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "        \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)]\n",
    "        if word[key] in V:\n",
    "            state.append(state_max)        \n",
    "        else:\n",
    "            rule_tag=rulebased_tagging(words[key])\n",
    "            state.append(rule_tag) \n",
    "                \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_rulebased(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    for key, word in enumerate(words):\n",
    "    #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        state_probability = 0\n",
    "        rule_tag = \"\"\n",
    "        if words[key] in V:\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "                # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)\n",
    "                state_probability = emission_p * transition_p\n",
    "                p.append(state_probability)\n",
    "            pmax = max(p)\n",
    "            state_max = T[p.index(pmax)]\n",
    "            state.append(state_max)\n",
    "            \n",
    "        else:\n",
    "            rule_tag=rulebased_tagging(words[key])\n",
    "            state.append(rule_tag)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9331499894224666\n",
      "CPU times: user 8min 37s, sys: 1.56 s, total: 8min 39s\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_seq1 = Viterbi_probabilistic(test_tagged_words)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq1, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tagged_seq2 = Viterbi_rulebased(test_tagged_words)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq2, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "# nltk.download('brown')\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "\n",
    "import requests\n",
    "response = requests.get('https://cdn.upgrad.com/UpGrad/temp/9dca5f3b-53c3-47e1-86d5-5ec5dafad6f0/Test_sentences.txt')\n",
    "data = response.text\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentense = sent_tokenize(data)\n",
    "word_sample= word_tokenize(data)\n",
    "\n",
    "\n",
    "# calculating tags using nltk.pos_tags, tagset universal\n",
    "\n",
    "tagged_data=nltk.pos_tag(word_sample,tagset='universal')\n",
    "# tagged_data\n",
    "sample_sent =list([pair[0] for pair in tagged_data])\n",
    "sample_sent[:5]\n",
    "tagged_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'CONJ'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN')]\n",
      "0.7624309392265194\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "tagged_seq3 = Viterbi_vanila(sample_sent)\n",
    "print(tagged_seq3[:5])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq3, tagged_data) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq3)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN')]\n",
      "0.8674033149171271\n"
     ]
    }
   ],
   "source": [
    "tagged_seq4 = Viterbi_probabilistic(sample_sent)\n",
    "print(tagged_seq4[:5])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq4, tagged_data) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq4)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN')]\n",
      "0.9281767955801105\n",
      "CPU times: user 16 s, sys: 98.5 ms, total: 16.1 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_seq5 = Viterbi_rulebased(sample_sent)\n",
    "print(tagged_seq5[:5])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq5, tagged_data) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq5)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
